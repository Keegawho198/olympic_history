{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbfbd35-f3b1-4595-ac36-f2168a6d719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271116"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv('resources/athlete_events.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de707e7-584c-452e-a455-b7536f58dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 1385\n",
      "Number of duplicate rows based on Name and Event: 63682\n"
     ]
    }
   ],
   "source": [
    "# Count duplicate rows based on all columns\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "# Alternatively, count duplicates based on specific columns (e.g., Name and Event)\n",
    "num_duplicates_specific = df.duplicated(subset=['Name', 'Event']).sum()\n",
    "print(f\"Number of duplicate rows based on Name and Event: {num_duplicates_specific}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb3d27a-e4b8-495c-9b5c-8877cbdd3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on all columns\n",
    "df_cleaned = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da4a43e-1f43-408d-bae7-5c396da68aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remaining duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for remaining duplicates in all columns\n",
    "remaining_duplicates = df_cleaned.duplicated().sum()\n",
    "print(f\"Number of remaining duplicate rows: {remaining_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac2c436-1122-4a37-85d6-546c43251359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269731"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac97f780-143b-4c61-b9cf-6b99411cdd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Count duplicate rows based on all columns\n",
    "num_duplicates = df_cleaned.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949a2224-46f2-4dbd-8a42-72a44017f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('cleaned_athlete_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920963b-ba3a-4cd5-9687-fb6d6750894e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
